{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMBccNVwEQJAj0O/Vy4O9lN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kholy/nlp_keras/blob/master/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngSg9AFWoiN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os,sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV0PBDAqon4j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f09bf32a-ac71-4fa8-840e-ddc9e2f4d5f7"
      },
      "source": [
        "!pip install rarfile"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rarfile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/0b/107dde3f330d04668e126932a09002ac47348841453aa0391634381fa087/rarfile-3.1.tar.gz (121kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: rarfile\n",
            "  Building wheel for rarfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rarfile: filename=rarfile-3.1-cp36-none-any.whl size=24908 sha256=24e733b5e873d179190b48fd20b9c953f8a3a2ecdd91b0926b2596f90346ff1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/3c/c8/0215b6a5079492eff3be3f545ae0b0c4a66734c35c9e444eac\n",
            "Successfully built rarfile\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVLpRLBoo1UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwpsHqYUpfEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWT_f0rxplOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1Oa5ID-hGfxPMutoOcz4YG2igh4dTDPzX\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('full_dataset-clean_tweets.rar')        # replace the file name with your file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChVReqCfqQ3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9df5aaf4-e193-4ea3-9c87-c08d9fec5126"
      },
      "source": [
        "import rarfile\n",
        "\n",
        "rf = rarfile.RarFile('full_dataset-clean_tweets.rar')\n",
        "for f in rf.infolist():\n",
        "  print (f.filename, f.file_size)\n",
        "  if f.filename == 'full_dataset-clean_tweets.json':\n",
        "    rf.extract(f,'./sample_data/full_dataset-clean_tweets.json')\n",
        "    #df = pd.read_json(rf.read(f), chunksize=100)\n",
        "    #for chunk in df:\n",
        "      #print(chunk)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "full_dataset-clean_tweets.json 10568097900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvxipJgHr0JA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb9ead01-4fa9-4839-82a7-67f4473a24e2"
      },
      "source": [
        "file_name='./sample_data/full_dataset-clean_tweets.json/full_dataset-clean_tweets.json'\n",
        "df = pd.read_json(file_name, lines=True,chunksize=10000)\n",
        "for chunk in df:\n",
        "  print(chunk)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                    created_at  ...  withheld_in_countries\n",
            "0    2020-01-04 00:03:43+00:00  ...                    NaN\n",
            "1    2020-01-04 05:23:50+00:00  ...                    NaN\n",
            "2    2020-01-06 14:54:46+00:00  ...                    NaN\n",
            "3    2020-01-08 14:30:20+00:00  ...                    NaN\n",
            "4    2020-01-08 18:35:16+00:00  ...                    NaN\n",
            "...                        ...  ...                    ...\n",
            "9995 2020-01-28 16:43:22+00:00  ...                    NaN\n",
            "9996 2020-01-28 16:43:27+00:00  ...                    NaN\n",
            "9997 2020-01-28 16:43:46+00:00  ...                    NaN\n",
            "9998 2020-01-28 16:44:05+00:00  ...                    NaN\n",
            "9999 2020-01-28 16:45:11+00:00  ...                    NaN\n",
            "\n",
            "[10000 rows x 33 columns]\n",
            "                     created_at  ...  withheld_in_countries\n",
            "10000 2020-01-28 16:45:23+00:00  ...                    NaN\n",
            "10001 2020-01-28 16:45:42+00:00  ...                    NaN\n",
            "10002 2020-01-28 16:46:13+00:00  ...                    NaN\n",
            "10003 2020-01-28 16:46:39+00:00  ...                    NaN\n",
            "10004 2020-01-28 16:47:49+00:00  ...                    NaN\n",
            "...                         ...  ...                    ...\n",
            "19995 2020-02-01 14:06:37+00:00  ...                    NaN\n",
            "19996 2020-02-01 14:08:38+00:00  ...                    NaN\n",
            "19997 2020-02-01 14:08:53+00:00  ...                    NaN\n",
            "19998 2020-02-01 14:10:20+00:00  ...                    NaN\n",
            "19999 2020-02-01 14:10:42+00:00  ...                    NaN\n",
            "\n",
            "[10000 rows x 31 columns]\n",
            "                     created_at  ...  quoted_status\n",
            "20000 2020-02-01 14:10:43+00:00  ...            NaN\n",
            "20001 2020-02-01 14:12:02+00:00  ...            NaN\n",
            "20002 2020-02-01 14:12:31+00:00  ...            NaN\n",
            "20003 2020-02-01 14:12:47+00:00  ...            NaN\n",
            "20004 2020-02-01 14:13:36+00:00  ...            NaN\n",
            "...                         ...  ...            ...\n",
            "29995 2020-02-07 20:44:12+00:00  ...            NaN\n",
            "29996 2020-02-07 20:47:29+00:00  ...            NaN\n",
            "29997 2020-02-07 20:48:08+00:00  ...            NaN\n",
            "29998 2020-02-07 20:48:31+00:00  ...            NaN\n",
            "29999 2020-02-07 20:50:05+00:00  ...            NaN\n",
            "\n",
            "[10000 rows x 30 columns]\n",
            "                     created_at  ...                                      quoted_status\n",
            "30000 2020-02-07 20:50:15+00:00  ...                                                NaN\n",
            "30001 2020-02-07 20:51:05+00:00  ...                                                NaN\n",
            "30002 2020-02-07 20:51:12+00:00  ...                                                NaN\n",
            "30003 2020-02-07 20:51:19+00:00  ...  {'created_at': 'Fri Feb 07 13:35:00 +0000 2020...\n",
            "30004 2020-02-07 20:52:25+00:00  ...                                                NaN\n",
            "...                         ...  ...                                                ...\n",
            "39995 2020-02-16 13:04:04+00:00  ...                                                NaN\n",
            "39996 2020-02-16 13:05:12+00:00  ...                                                NaN\n",
            "39997 2020-02-16 13:08:56+00:00  ...                                                NaN\n",
            "39998 2020-02-16 13:10:07+00:00  ...                                                NaN\n",
            "39999 2020-02-16 13:10:27+00:00  ...  {'created_at': 'Sun Feb 16 09:36:55 +0000 2020...\n",
            "\n",
            "[10000 rows x 30 columns]\n",
            "                     created_at  ...  withheld_in_countries\n",
            "40000 2020-02-16 13:10:42+00:00  ...                    NaN\n",
            "40001 2020-02-16 13:12:33+00:00  ...                    NaN\n",
            "40002 2020-02-16 13:12:51+00:00  ...                    NaN\n",
            "40003 2020-02-16 13:14:24+00:00  ...                    NaN\n",
            "40004 2020-02-16 13:16:14+00:00  ...                    NaN\n",
            "...                         ...  ...                    ...\n",
            "49995 2020-02-24 08:24:32+00:00  ...                    NaN\n",
            "49996 2020-02-24 08:24:33+00:00  ...                    NaN\n",
            "49997 2020-02-24 08:25:13+00:00  ...                    NaN\n",
            "49998 2020-02-24 08:25:55+00:00  ...                    NaN\n",
            "49999 2020-02-24 08:26:13+00:00  ...                    NaN\n",
            "\n",
            "[10000 rows x 31 columns]\n",
            "                     created_at  ...  withheld_in_countries\n",
            "50000 2020-02-24 08:26:22+00:00  ...                    NaN\n",
            "50001 2020-02-24 08:26:31+00:00  ...                    NaN\n",
            "50002 2020-02-24 08:26:34+00:00  ...                    NaN\n",
            "50003 2020-02-24 08:26:46+00:00  ...                    NaN\n",
            "50004 2020-02-24 08:27:14+00:00  ...                    NaN\n",
            "...                         ...  ...                    ...\n",
            "59995 2020-02-26 18:01:06+00:00  ...                    NaN\n",
            "59996 2020-02-26 18:01:32+00:00  ...                    NaN\n",
            "59997 2020-02-26 18:01:35+00:00  ...                    NaN\n",
            "59998 2020-02-26 18:01:35+00:00  ...                    NaN\n",
            "59999 2020-02-26 18:01:49+00:00  ...                    NaN\n",
            "\n",
            "[10000 rows x 31 columns]\n",
            "                     created_at  ...  withheld_in_countries\n",
            "60000 2020-02-26 18:02:05+00:00  ...                    NaN\n",
            "60001 2020-02-26 18:02:28+00:00  ...                    NaN\n",
            "60002 2020-02-26 18:03:13+00:00  ...                    NaN\n",
            "60003 2020-02-26 18:03:30+00:00  ...                    NaN\n",
            "60004 2020-02-26 18:03:44+00:00  ...                    NaN\n",
            "...                         ...  ...                    ...\n",
            "69995 2020-02-28 10:20:52+00:00  ...                    NaN\n",
            "69996 2020-02-28 10:20:52+00:00  ...                    NaN\n",
            "69997 2020-02-28 10:21:00+00:00  ...                    NaN\n",
            "69998 2020-02-28 10:21:21+00:00  ...                    NaN\n",
            "69999 2020-02-28 10:22:46+00:00  ...                    NaN\n",
            "\n",
            "[10000 rows x 31 columns]\n",
            "                     created_at  ...  extended_entities\n",
            "70000 2020-02-28 10:23:01+00:00  ...                NaN\n",
            "70001 2020-02-28 10:23:20+00:00  ...                NaN\n",
            "70002 2020-02-28 10:23:51+00:00  ...                NaN\n",
            "70003 2020-02-28 10:23:58+00:00  ...                NaN\n",
            "70004 2020-02-28 10:24:41+00:00  ...                NaN\n",
            "...                         ...  ...                ...\n",
            "79995 2020-03-01 00:33:48+00:00  ...                NaN\n",
            "79996 2020-03-01 00:34:03+00:00  ...                NaN\n",
            "79997 2020-03-01 00:34:28+00:00  ...                NaN\n",
            "79998 2020-03-01 00:35:04+00:00  ...                NaN\n",
            "79999 2020-03-01 00:35:11+00:00  ...                NaN\n",
            "\n",
            "[10000 rows x 30 columns]\n",
            "                     created_at  ...  withheld_in_countries\n",
            "80000 2020-03-01 00:35:38+00:00  ...                    NaN\n",
            "80001 2020-03-01 00:35:44+00:00  ...                    NaN\n",
            "80002 2020-03-01 00:35:55+00:00  ...                    NaN\n",
            "80003 2020-03-01 00:36:10+00:00  ...                    NaN\n",
            "80004 2020-03-01 00:36:22+00:00  ...                    NaN\n",
            "...                         ...  ...                    ...\n",
            "89995 2020-03-03 05:07:02+00:00  ...                    NaN\n",
            "89996 2020-03-03 05:07:28+00:00  ...                    NaN\n",
            "89997 2020-03-03 05:07:49+00:00  ...                    NaN\n",
            "89998 2020-03-03 05:07:52+00:00  ...                    NaN\n",
            "89999 2020-03-03 05:08:10+00:00  ...                    NaN\n",
            "\n",
            "[10000 rows x 31 columns]\n",
            "                     created_at  ...  quoted_status\n",
            "90000 2020-03-03 05:08:55+00:00  ...            NaN\n",
            "90001 2020-03-03 05:09:11+00:00  ...            NaN\n",
            "90002 2020-03-03 05:09:16+00:00  ...            NaN\n",
            "90003 2020-03-03 05:10:48+00:00  ...            NaN\n",
            "90004 2020-03-03 05:10:58+00:00  ...            NaN\n",
            "...                         ...  ...            ...\n",
            "99995 2020-03-04 22:49:00+00:00  ...            NaN\n",
            "99996 2020-03-04 22:49:10+00:00  ...            NaN\n",
            "99997 2020-03-04 22:49:13+00:00  ...            NaN\n",
            "99998 2020-03-04 22:49:18+00:00  ...            NaN\n",
            "99999 2020-03-04 22:49:24+00:00  ...            NaN\n",
            "\n",
            "[10000 rows x 30 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_iFHV3A0Ly7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1dd1e3d4-b7d4-4a84-e7da-c40b86df60b0"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json                         full_dataset-clean_tweets.rar\n",
            "\u001b[0m\u001b[01;34mfull_dataset-clean_tweets.json\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbXrtyrl-aBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "30a04df6-e9b2-40ab-f04c-76a2b2674fc3"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "for path, subdirs, files in os.walk('./sample_data'):\n",
        "    for name in files:\n",
        "        print(os.path.join(path, name)) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./sample_data/README.md\n",
            "./sample_data/anscombe.json\n",
            "./sample_data/california_housing_test.csv\n",
            "./sample_data/mnist_train_small.csv\n",
            "./sample_data/california_housing_train.csv\n",
            "./sample_data/mnist_test.csv\n",
            "./sample_data/full_dataset-clean_tweets.json/full_dataset-clean_tweets.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5cuLtep8PeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}